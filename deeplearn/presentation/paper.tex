\documentclass[10pt]{amsart}
\usepackage{amsmath}

\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathcal{C}}

\begin{document}
\title{Recurrent Neural Networks}
\author{Jean-Martin Albert}
\date{\today}
\maketitle

\section{The basic problem}

Let $U=\R^n$ and $V=\R^m$ be vector spaces, and consider a function $f:U\to W$.
In theory, $f$ here can be any set theoretic function, but for our purpose, we
will assume that $f$ is at the very least square integrable. In general, we
consider a class $\C$ of functions $U\to V$, and try to find an element $g\in\C$
which is as close as possible to $f$.  In order to do so, we need a notion of distance
between functions.  There are many possible choices, but some of the most popular are
the $L^p$ norms and the $L^\infty$ norm.

While the class $\C$ van be virtually any class of functions, we usually choose a class
that is somewhat definable, in the sense that there is a (differentiable) function $F:U\times\R^k\to V$
such that $\C=\{F(x, w): w\in \R^k\}$.  Such classes of functions have the advantage of
being equicontinuous.


%\begin{example}
Let $f(x)=x(x-1)(x+1)$.  As an example, we will try to fit a linear function
$\ell(x)=ux+v$ to $f$.  The class $\C$ is defined by $\C=\{ux+v:u,v\in R\}$.
For an element $g(x, u, v)\in\C$, we have $$f(x)-g(x,u,v) = x^3-x - ux+v$$
From this we get
\begin{eqnarray*}
  (f(x)-g(x,u,v))^2 &=& (x^3 - (1-u)x + v)^2 \\
  {} &=& x^6 - 2(1-u)x^4 + 2vx^3 + (1-u)^2x^2 - \\
  {} & & 2(1-u)vx + v^2
\end{eqnarray*}
If we compute $\int_{-1}^1 (f(x)-g(x,u,v))^2$, we get

\begin{eqnarray*}
  \int_{-1}^1(f(x)-g(x; u,v))^2 &=& \int_{-1}^1(x^3 - (1-u)x + v)^2 \\
  {} &=& \int_{-1}^1x^6 - 2(1-u)x^4 + 2vx^3 + (1-u)^2x^2 - 2(1-u)vx + v^2\\
  {} &=& \frac{x^7}{7}-2v\frac{x^4}{4} + (1-u)^2\frac{x^3}{3} - 2(1-u)v\frac{x^2}{2}+v^2x\\
  {} &=& \frac{1}{7}-2v\frac{1}{4} + (1-u)^2\frac{1}{3} - 2(1-u)v\frac{1}{2}+v^2\\
  {} & & +\frac{1}{7}-2v\frac{1}{4} + (1-u)^2\frac{-1}{3} - 2(1-u)v\frac{1}{2}-v^2\\
  {} &=& \frac{2}{7} - (2-u)v+v^2 = \ell(u,v)
\end{eqnarray*}
and note that the last line above is a function of $u$ and $v$ alone, and we have to minimize it.
%\end{example}


\section{Dealing with sequences}



\end{document}
